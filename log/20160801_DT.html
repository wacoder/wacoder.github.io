<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Wacoder&#39;s Blog by wacoder</title>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1">


<meta name="description" content="" />

<meta name="keywords" content="">

<meta property="og:locale" content="en-EN">


<meta property="og:type" content="website" />

      <link href="https://wacoder.github.io/theme/bootstrap.min.css" rel="stylesheet">
      <link href="https://wacoder.github.io/theme/bootstrap.min.responsive.css" rel="stylesheet">
      <link href="https://wacoder.github.io/theme/local.css" rel="stylesheet">
      <link href="https://wacoder.github.io/theme/pygments.css" rel="stylesheet">
      <link href='https://fonts.googleapis.com/css?family=Merriweather:300%7CRaleway%7COpen+Sans' rel='stylesheet' type='text/css'>
      <link rel="stylesheet" href="https://wacoder.github.io/theme/font-awesome.min.css">
      <link rel="stylesheet" href="https://wacoder.github.io/theme/style.css">
      <link rel="stylesheet" href="https://wacoder.github.io/theme/tomorrow.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
<body>


<div class="container">
    <div class="content">
    <div class="row">

        <div class="span9">
    <div class='article'>
        <div class="content-title">
            <h1>A Complete Handbook on Decision Tree</h1>
            <div class= "well small">
            July 11 2016

            by <a class="url fn" href="https://wacoder.github.io/">wacoder</a>

            Tags <a class="url fn" href="https://wacoder.github.io/tag/basics.html">Basics</a>
            </div>
</div>
<div><p><b>Desicion Tree</b>s are a non-parametric supervised learning method used for classifcation and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data.</p>

  <h3>1. What is a Decision Tree? How does it work?</h3>
<p></p>
<p>Decision tree is a type of supervised learning algorithm (having a pre-defined target varialbe) that is mostly used in classification problems. It works for both categorical and continous input and output variables. In this technique, we split the population or sample into two or more homogeneous sets based on most significant splitter in input variables.</p>
<p></p>
  <h4>Important terminology related to decision tree</h4>
<p>
  <ul>
<li><b>Leaf/Terminal Node</b>: nodes do not split is called leaf node.</li>
<li><b>Decision Node</b>: decision node is a question on features, it branches out according to answers.</li>
<li><b>Pruning</b>: when we remove the sub-nodes of a decison node, this process is called pruning. You can say opposite process of splitting.</li>
</ul>
</p>
<center><img src="image/dt.PNG"></center>
<p></p>

<h4>Advantages</h4>
<p>
<ul>
<li><b>Simple to understand and to interpret</b>. Trees can be visulized.</li>
<li><b>Requires little data preparation</b>. It requires less data cleaning compared to some other modeling technique.</li>
<li><b>Able to handle both numerical and categorical data</b>.</li>
<li><b>No parametric method</b>. Decision tree is considered to be a non-parametric method. This means that decision tree have no asumption about space distribution and the classfier structure.</li>
</ul>
</p>

<h4>Disadvantages</h4>
<p>
<ul>
<li><b>Overfitting</b>. Decision tree can create over complex tree that do not generalize the data well.</li>
</ul>
</p>
<h3>2. How to build the tree?</h3>
<p>The decision of making strategic splits heavily affects a tree's accuracy. There are many measures that can by used to determine the best way to split the samples. The creation of sub-nodes increases the homogeneity of resultant sub-nodes. In other words, we can say that purity of the node increases with respect to the target variables. Decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub-nodes.</p>
<p>Let <span class="math">\(p(i/t)\)</span> denote the fraction of samples belonging to class <span class="math">\(i\)</span> at a given node <span class="math">\(t\)</span>.</p>
<p></p>
<h4>Gini index</h4>
<p>
<ul>
<li><b>a.</b> calcuate Gini for sub-nodes, using the formula.
<span class="math">\(Gini(t)=1-\sum[p(i/t)]^2\)</span>
</li>

<li><b>b.</b> calculate Gini for split using weighted Gini score of each node of that split.  
</li>
</ul>
</p>

<p>Used for measure of centre; affected by outliers </p>
<table class="table">
    <tbody>
      <tr><td>Population mean</td><td>Sample mean</td></tr>
        <tr>
        <td><span class="math">\(\mu=\frac{1}{N}\sum_{i=1}^{N}x_i\)</span></td> <td><span class="math">\(\bar{x}=\frac{1}{n}\sum_{i=1}^{n}x_i\)</span></td>
        </tr>

    </tbody>
</table>

<h4>3. Variance</h4>
<p>Used for measure of variation </p>
<table class="table">
    <tbody>
      <tr><td>Population variance</td><td>Sample variance</td></tr>
        <tr>
        <td><span class="math">\(\delta^2=\frac{\sum(x-\mu)^2}{N}\)</span></td> <td><span class="math">\(s^2=\frac{\sum(x-\bar{x})^2}{n-1}\)</span></td>
        </tr>

    </tbody>
</table>

<h4>4. Correlation coefficient</h4>
<p>Pearson correlation (r)</p>
<p><span class="math">\(r=\frac{1}{n-1}\frac{\sum(x-\bar{x})(y-\bar{y})}{s_x s_y}\)</span></p>

  <h3>Handling statistical hypothesis tests</h3>
  <p></p>
  <h4>1. Z-statistic</h4>
  <p>Used when the standard deviation is known. The sample must be drawn from a normal distribution or have a sample size (n) at least 30.</p>
  <p><span class="math">\(z=\frac{\bar{x}-\mu}{\delta/\sqrt{n}}\)</span>, where <span class="math">\(\mu\)</span> = population mean (either known or hypothesis under <span class="math">\(H_{o}\)</span>)</p>
  <p><b>Confidence interval</b>-Interval within which we may consider a hypothesis tenable. Common confidence intervals are 90%, 95% and 99%.</p>
  <p><span class="math">\(1-\alpha\)</span> confidence interval for <span class="math">\(\mu\)</span>:</p>
  <p><span class="math">\(\bar{x}-z_{\alpha/2}(\delta/\sqrt{n})\leq\mu\leq\bar{x}+z_{\alpha/2}(\delta/\sqrt{n})\)</span></p>
  <p>where <span class="math">\(z_{\alpha/2}\)</span> is the value of the standard normal variable z that puts <span class="math">\(\alpha/2\)</span> percent in each tail of the distribution.</p>

  <p></p>
  <h4>2. t-statistic</h4>
  <p>Used when the standard deviation is unknown. use of Student's t distribution.</p>
  <p><b>One sample</b>: tests whether the mean of a normally distributed population is different from a specified value.</p>
  <p><span class="math">\(t=\frac{\bar{x}-\mu}{s/\sqrt{n}}\)</span>, where degree of freedom (df) = n-1</p>
  <p><b>Two samples</b>: tests whether the means of two populations are significantly different from one another.</p>
  <p><span class="math">\(t=\frac{\bar{x_1}-\bar{x_2}}{\sqrt{\frac{{s_1}^2}{n_1}+\frac{{s_2}^2}{n_2}}}\)</span>, where degree of freedom (df) = <span class="math">\(n_1+n_2-2\)</span></p>

  <p></p>
  <p></p>
  <h4>3. Analysis of variance (ANOVA)</h4>
  <p><span class="math">\(H_{o}:\mu_1=\mu_2=\mu_3\)</span></p>
  <p><span class="math">\(H_{1}:\)</span>at least one pair of samples is significantly different.</p>
  <p>Grand mean <span class="math">\(\bar{x}_G \)</span>(mean of sample mean)</p>
  <p><span class="math">\(\bar{x}_G=\frac{\bar{x}_1+\dots+\bar{x}_k}{k}\)</span></p>
  <p><b>Between-Group Variance</b>- reflects the magnitude of differences among the group means.</p>
  <p><span class="math">\(BGV=\frac{\sum n_k(\bar{x}_k-\bar{x}_G)^2}{K-1}\)</span>, where <span class="math">\(n_k\)</span> is the sample size of each group, <span class="math">\(K\)</span> is the group number.</p>

  <p><b>Within-Group Variance</b>- reflects the dispersion within each group.</p>
  <p><span class="math">\(WGV=\frac{\sum\sum(x_i-\bar{x}_k)^2}{N-K}\)</span>, where <span class="math">\(N\)</span> is the total number of all groups, <span class="math">\(K\)</span> is the group number.</p>

  <p><b>Use F-ratio</b>: <span class="math">\(F=\frac{BGV}{WGV}\)</span>, where degree of freedom is K-1 and N-K</p>

  <p></p>
  <p></p>
  <h4>4. Chi-squared test</h4>
  <p><b>For goodness of fit:</b>Checks whether or not an observed pattern of data fits some given distribution.</p>
  <p><span class="math">\(\chi^2=\sum\frac{(O-E)^2}{E}\)</span>, where O is the observed value and E is the expected value</p>
<p>Degrees of freedom = number of categories in the distribution -1</p>
  <p></p>
<p><b>For independence:</b>Checks whether two categorical variables are related or not.</p>
<p><span class="math">\(\chi^2=\sum\frac{(O-E)^2}{E}\)</span>, where O is the observed value and E is the expected value.  </p>
<p>Degrees of freedom = (r-1)(c-1), r is the number of rows and c is the number of columns.</p>


<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' }, Macros: {} }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></div>


    </div>
        </div>

        <div class="span3">

            <div class="well" style="padding: 8px 0; background-color: #FFFFFF;">
            <ul class="nav nav-list">
                <li class="nav-header">
                Site Map
                </li>

              </div>
              <nav class="container title h2-like">
              <a href="https://wacoder.github.io/" title="all posts">Home</a>
              </nav>


              <nav class="container title h2-like">
              <a href="https://wacoder.github.io/archives.html" title="all posts">Archives</a>
              </nav>
              <nav class="container title h2-like">
              <a href="https://wacoder.github.io/tags.html" title="Categories">Tags</a>
              </nav>

            </ul>
            </div>
        </div>
    </div>     </div>

</div> <!-- /container -->
</body>
</html>
